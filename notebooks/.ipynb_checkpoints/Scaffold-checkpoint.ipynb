{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7240cd-139b-4e57-8284-50202059ff72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maxime/dev/python/sndx/.venv/bin/python3.12\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6b106972-f8df-4c01-9b57-d8174a0d49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "import sndx\n",
    "from sndx import Scrapper\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "from pyppeteer import launch\n",
    "from queue import Queue\n",
    "import yaml\n",
    "import re\n",
    "\n",
    "CHROMIUM_PATH = os.environ.get(\"CHROMIUM_PATH\")\n",
    "ROOT_URL = \"https://vod.catalogue-crc.org\"\n",
    "CATEGORIES_URL = \"https://vod.catalogue-crc.org/categorie.html\"\n",
    "\n",
    "def parse_duration(s: str) -> int:\n",
    "    parts = list(map(int, s.split(\":\")))\n",
    "    if len(parts) == 3:\n",
    "        h, m, sec = parts\n",
    "    elif len(parts) == 2:\n",
    "        h = 0\n",
    "        m, sec = parts\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid duration format: {s}\")\n",
    "\n",
    "    seconds = h * 3600 + m * 60 + sec\n",
    "    return timedelta(seconds=seconds)\n",
    "\n",
    "\n",
    "\n",
    "def safe_filename(s):\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", s)\n",
    "    return s or \"file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e04dfad-21e1-4f68-a236-e0d9ce3e5d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening sink sndx-FBFXmg\n",
      "[RecordingScrapper-ZbkGiQ] Starting with profile [sndx-profile-1] and sink [sndx-FBFXmg]...\n",
      "Doing stuff\n",
      "Stuff finished\n",
      "[RecordingScrapper-ZbkGiQ] Terminating...\n",
      "Closing sink sndx-FBFXmg\n"
     ]
    }
   ],
   "source": [
    "profile = \"sndx-profile-1\"\n",
    "\n",
    "with sndx.Sink() as sink:\n",
    "    async with sndx.RecordingScrapper(profile, sink, headless=False) as scrapper:\n",
    "        print(\"Doing stuff\")\n",
    "        await asyncio.sleep(3)\n",
    "        print(\"Stuff finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "30114b9e-f536-4924-aeb4-70441ce2b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_category_url(url):\n",
    "    return url.startswith(\"https://vod.catalogue-crc.org/categorie/\")\n",
    "\n",
    "def is_serie_url(url):\n",
    "    return url.startswith(\"https://vod.catalogue-crc.org/serie/\")\n",
    "\n",
    "def is_recording_url(url):\n",
    "    return url.startswith(\"https://vod.catalogue-crc.org/enregistrement/\")\n",
    "\n",
    "\n",
    "class Link:\n",
    "    def __init__(self, url, text):\n",
    "        self.url = url\n",
    "        self.text = text\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"[{self.text}]({self.url})\"\n",
    "\n",
    "\n",
    "class CategoryMetadata:\n",
    "    def __init__(self, url, title, categories):\n",
    "        self.url = url\n",
    "        self.title = title\n",
    "        self.categories = categories\n",
    "\n",
    "\n",
    "class MetadataScrapper(Scrapper):\n",
    "    def __init__(self, profile_id, outdir, headless=True):\n",
    "        super().__init__(profile_id, headless)\n",
    "        self.outdir = Path(outdir).resolve()\n",
    "        self.categories_dir = self.outdir / \"categories\"\n",
    "        self.recordings_dir = self.outdir / \"recordings\"\n",
    "        self.url_queue = None\n",
    "        self.visited = None\n",
    "\n",
    "    \n",
    "    async def open(self):\n",
    "        print(f\"[MetadataScrapper-{self.id}] Starting with profile [{self.profile_id}]...\")\n",
    "        self.browser = await launch(\n",
    "            headless=self.headless,\n",
    "            executablePath=CHROMIUM_PATH,\n",
    "            userDataDir=self.profile_path)\n",
    "        pages = await self.browser.pages()\n",
    "        self.page = pages[0]\n",
    "\n",
    "    async def close(self):\n",
    "        print(f\"[MetadataScrapper-{self.id}] Terminating...\")\n",
    "        await self.browser.close()\n",
    "\n",
    "\n",
    "    async def crawl(self):\n",
    "        await self.initialize()\n",
    "        \n",
    "        #while not self.queue.empty():\n",
    "        #    url = self.queue.get()\n",
    "        #    await self.process_resource_url(url)\n",
    "        #    self.visited.add(url)\n",
    "        #    self.queue.task_done()\n",
    "\n",
    "\n",
    "    async def initialize(self):\n",
    "        self.log(f\"Initializing...\")\n",
    "        self.queue = Queue()\n",
    "        self.visited = set()\n",
    "\n",
    "        self.categories_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.recordings_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        await self.page.goto(CATEGORIES_URL)\n",
    "        urls = await self.queue_resource_urls()   \n",
    "\n",
    "    \n",
    "    async def queue_resource_urls(self):\n",
    "        new = 0\n",
    "        for url in await self.extract_resource_urls():\n",
    "            if url not in self.visited:\n",
    "                self.queue.put(url)\n",
    "                new += 1\n",
    "        self.log(f\"Found {new} new resource URLs.\")\n",
    "\n",
    "    \n",
    "    async def process_resource_url(self, url):\n",
    "        self.log(f\"Scrapping [{url}]...\")\n",
    "        await self.page.goto(url)\n",
    "        \n",
    "        await self.queue_resource_urls()\n",
    "\n",
    "        if is_category_url(url) or is_serie_url(url):\n",
    "            await self.extract_category_metadata()\n",
    "        elif is_recording_url(url):\n",
    "            await self.extract_recording_metadata()\n",
    "\n",
    "\n",
    "    async def extract_category_metadata(self):\n",
    "        url = await self.page.evaluate('() => window.location.href')\n",
    "        breadcrumbs = await page.xpath(\"//ul[@class='uk-breadcrumb']//li\")\n",
    "        title = await scrapper.get_text(breadcrumbs[-1])\n",
    "        categories = await self.extract_parent_categories()\n",
    "\n",
    "        data = {\n",
    "            \"url\": url,\n",
    "            \"title\": title,\n",
    "            \"categories\": [{ \"url\": l.url, \"title\": l.text } for l in categories],\n",
    "        }\n",
    "\n",
    "        filename = safe_filename(f\"{title}.yaml\")\n",
    "        filepath = self.categories_dir / filename\n",
    "\n",
    "        with open(filepath, \"w\") as f:\n",
    "            yaml.dump(data, f, sort_keys=False)\n",
    "\n",
    "        self.log(f\"Extracted category metadata in file [{filepath}].\")\n",
    "\n",
    "\n",
    "    async def extract_parent_categories(self):\n",
    "        breadcrumbs = await page.xpath(\"//ul[@class='uk-breadcrumb']//li\")     \n",
    "        categories = []\n",
    "        for elem in breadcrumbs[2:-1]:\n",
    "            a = (await elem.xpath(\".//a\"))[0]\n",
    "            url = await (await a.getProperty(\"href\")).jsonValue()\n",
    "            text = await (await a.getProperty(\"textContent\")).jsonValue()\n",
    "            categories.append(Link(url, text))\n",
    "\n",
    "        return categories\n",
    "    \n",
    "\n",
    "    async def extract_recording_metadata(self):\n",
    "        url = await self.page.evaluate('() => window.location.href')\n",
    "        categories = await self.extract_parent_categories()\n",
    "        title = await self.get_first(\"//h1[preceding-sibling::*[2][self::h3]]\")\n",
    "        subtitle = await self.get_first(\"//h2[preceding-sibling::*[3][self::h3]]\")\n",
    "\n",
    "        details = await page.xpath(\"//ul[@id='details']//li[@class='uk-active']//dd\")\n",
    "        code = (await self.get_text(details[0])).strip()\n",
    "        date = (await self.get_text(details[-4])).strip()\n",
    "        place = (await self.get_text(details[-3])).strip()\n",
    "        authors = [s.strip() for s in (await self.get_text(details[-2])).split(\"<br/>\")]\n",
    "        duration_str = (await self.get_text(details[-1])).strip()\n",
    "\n",
    "        summary = await scrapper.get_first(\"//li[@class='PromptuairePublication']//p\")\n",
    "\n",
    "        data = {\n",
    "            \"url\": url,\n",
    "            \"code\": code,\n",
    "            \"title\": title,\n",
    "            \"subtitle\": subtitle,\n",
    "            \"categories\": [{ \"url\": l.url, \"title\": l.text } for l in categories],\n",
    "            \"date\": date,\n",
    "            \"place\": place,\n",
    "            \"authors\": authors,\n",
    "            \"duration\": duration_str,\n",
    "            \"duration-seconds\": parse_duration(duration_str).seconds,\n",
    "            \"summary\": summary,\n",
    "        }\n",
    "\n",
    "        filename = safe_filename(f\"{code}-{title}.yaml\")\n",
    "        filepath = self.recordings_dir / filename\n",
    "\n",
    "        with open(filepath, \"w\") as f:\n",
    "            yaml.dump(data, f, sort_keys=False)\n",
    "\n",
    "        self.log(f\"Extracted recording metadata in file [{filepath}].\")\n",
    "        \n",
    "\n",
    "    async def extract_resource_urls(self):\n",
    "        urls = []\n",
    "        for elem in await page.xpath(\"//a\"):\n",
    "            urls.append(await (await elem.getProperty(\"href\")).jsonValue())\n",
    "            \n",
    "        return [u for u in urls if is_category_url(u) or is_serie_url(u) or is_recording_url(u)]\n",
    "\n",
    "\n",
    "    def log(self, msg):\n",
    "        print(f\"[MetadataScrapper-{self.id}] {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e7e2c302-e8c1-4003-aae1-ed38a0a09df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MetadataScrapper-Tap3KQ] Starting with profile [sndx-profile-1]...\n"
     ]
    }
   ],
   "source": [
    "profile = \"sndx-profile-1\"\n",
    "outdir = Path(\"/home/maxime/.local/share/sndx\")\n",
    "\n",
    "scrapper = MetadataScrapper(profile, outdir, headless=False)\n",
    "await scrapper.open()\n",
    "browser = scrapper.browser\n",
    "page = scrapper.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dbde3732-7226-4397-a1a2-aaec0322fe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MetadataScrapper-LejD1g] Terminating...\n"
     ]
    }
   ],
   "source": [
    "await scrapper.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c604e400-edde-4739-9153-8b35d7a4235c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MetadataScrapper-Tap3KQ] Initializing...\n",
      "[MetadataScrapper-Tap3KQ] Found 48 new resource URLs.\n"
     ]
    }
   ],
   "source": [
    "await scrapper.crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7931a0f1-6cd5-4d93-a5f2-f2b1eea9746e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MetadataScrapper-Tap3KQ] Extracted recording metadata in file [/home/maxime/.local/share/sndx/recordings/PI_4_28.1-Face_aux_plaies_du_Christ..yaml].\n"
     ]
    }
   ],
   "source": [
    "await scrapper.extract_recording_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ff807946-3c2b-4279-97a2-6345c56c3e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queued: 48\n",
      "Visited: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Queued: {scrapper.queue.qsize()}\")\n",
    "print(f\"Visited: {len(scrapper.visited)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0eb4e086-5519-439d-950b-6f2ec79362d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C’est un véritable roman d’aventure que la vie du frère Flavien Laplante, missionnaire au Bangladesh\\xa0! Dans cette première partie, frère Pierre raconte la jeunesse, l’affermissement de la vocation et les débuts missionnaires de ce religieux canadien, bien selon le cœur du pape François. Mais quel est le secret de ce travailleur acharné, ami des humbles, bâtisseur et directeur d’école... terreur des pirates\\xa0? L’amour de la Sainte Vierge.'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = await scrapper.get_first(\"//li[@class='PromptuairePublication']//p\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2292181-abc9-459a-a535-0e9e2d06e28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MetadataScrapper-PPuNfg] Terminating...\n"
     ]
    }
   ],
   "source": [
    "await scrapper.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cee8d1e9-1541-4118-b335-c0878c4d52c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyppeteer.element_handle.ElementHandle at 0x7fffd90f7fe0>]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.xpath(\"//li[@class='PromptuairePublication']//p\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5eb76-cf8d-473c-a54b-baf458c3e133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
